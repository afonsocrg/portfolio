# Report

## System Model

We consider an asynchronous, fail-silent arbitrary model where we implement the perfect links.

Byzantine users can behave badly in several ways:

* Witnessing an invalid record **(1)**
* Rejecting a valid record **(2)**
* Asking for proofs to users that are not near them **(3)**
* Sending wrong reports to the server **(4)**
* Try to forge a proof on behalf of another user, either for himself or another byzantine user **(5)**
* Share its private key with other malicious users **(6)**
* Create, duplicate and change the contents of any message **(7)**
* Suppress the sending of any message **(8)**
* Close connections **(9)**
* Execute man in the middle attacks **(10)**

**NOTE:** In this report, `f` means the maximum number of byzantine users that the system can have, and `f'` the maximum number of byzantine users **around** a certain user.

## Secure Channel

Secure Channel provably prevents outside attackers from forging messages on behalf of inside users. This property is ensured by the assumption that keys have been securely generated, distributed and stored. Although knowing all the keys of other users is not scalable in a real-world application, this setback is easily overcome by sharing a certificate in the beginning of every communication. The trusted authority would be the owner of this product, which would be responsible for generating new client certificates. These certificates would include the subject's public key (*ku*), its unique ID and role, which would grant him permissions at the server-side.

The secure channel ensures integrity, non-repudiation, and, optionally, confidentiality:

* The integrity and non-repudiation of the message are assured by signing the plaintext content.
* Users can opt to have their messages ciphered. If so, after assuring the  integrity, confidentiality is assured by a hybrid cipher (AES + RSA).

These properties assure that each message was created by the user who claimed to do so.
External attacks will be detected, thus we only need to focus on dealing with byzantine users.

Replay attacks were considered harmless because every operation in this system is idempotent. By replaying queries, an attacker could obtain several ciphertexts of the same information and try to use cryptanalysis to break the confidentiality of the messages. We did not address this, as we rely on the security of the used cryptographic primitives.

## Implemented protocol

In this system, each user generates a Record at each epoch. Every witness that corroborates that record signs it with its private key (*kr*) and sends that signature back to the requester (alongside the witness id). We know that each proof is only valid for a unique request and that it could only be generated by a single correct user, as we use a collision resistant hashing function and public-key cryptography. When the requester has enough proofs, it sends them alongside the Record to the server which then validates every proof (rejects duplicate proofs from the same witness and those that do not sign the record). If they meet the requirements, the record and proofs are safely stored in the database. Since the user signs its own records, it cannot deny having sent the record.

Users need to continuously try to send messages to other users/server while not receiving a response, since a byzantine user can drop packets.

Any report is valid iff it contains at least one proof from any correct user. Since each user is surrounded by, at most, `f'` byzantine users we need, at least `f'+1` proofs. However, because of **(6)**, any byzantine user could forge at most `f` proofs. Thus a report is valid iff it contains at least `f+1` proofs.
This raises a problem. The constraint only guarantees that a user can always generate a valid report if it has at least `f+f'+1` neighbors: In this case, even if the `f'` byzantine users reject a valid record, the user would get at least `f+1` proofs. Otherwise, the user will keep requesting proofs and eventually create a valid report. This is a cost we are willing to take in order to tolerate the modeled byzantine users.

Users also validate the proofs they receive in an attempt to minimize the server load.

We don't require one entity to prove its identity because every bit of information will be ciphered with the requested identity's public key. One possible attack would be to assume the identity of a target and collect as much ciphered information as possible so that in a future occasion of a private key leak, the data could then be deciphered, rendering key revocations useless. We consider this problem to be out of the scope of this course.
